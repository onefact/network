{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to the directory containing the CSV files\n",
    "data_path = \"/Users/tommyly/network/data/embeddingdata/opencorporates/us_ny_unzipped\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a CSV file\n",
    "def load_csv(file_name):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    return pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Load each file into a separate DataFrame\n",
    "additional_identifiers_df = load_csv('additional_identifiers.csv')\n",
    "alternative_names_df = load_csv('alternative_names.csv')\n",
    "companies_df = load_csv('companies.csv')\n",
    "non_reg_addresses_df = load_csv('non_reg_addresses.csv')\n",
    "officers_df = load_csv('officers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "officers_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_reg_addresses_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_names_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_identifiers_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group officers by company and analyze positions\n",
    "officer_hierarchy = officers_df.groupby('company_number')['position'].value_counts().unstack()\n",
    "\n",
    "# Look at the distribution of positions across companies\n",
    "position_distribution = officers_df['position'].value_counts()\n",
    "\n",
    "print(position_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of officers per company\n",
    "officers_per_company = officers_df.groupby('company_number').size().sort_values(ascending=False)\n",
    "\n",
    "print(officers_per_company.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the types and frequency of alternative names\n",
    "name_types = alternative_names_df['type'].value_counts()\n",
    "\n",
    "print(name_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of companies across countries and regions\n",
    "country_distribution = companies_df['registered_address.country'].value_counts()\n",
    "region_distribution = companies_df['registered_address.region'].value_counts()\n",
    "\n",
    "print(\"Top 10 countries:\")\n",
    "print(country_distribution.head(10))\n",
    "print(\"\\nTop 10 regions:\")\n",
    "print(region_distribution.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'branch' column indicates subsidiaries\n",
    "if 'branch' in companies_df.columns:\n",
    "    branch_counts = companies_df['branch'].value_counts()\n",
    "    print(\"Branch types:\")\n",
    "    print(branch_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "# Convert CSV to Parquet\n",
    "def csv_to_parquet(csv_path, parquet_path):\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, parquet_path)\n",
    "\n",
    "# Convert all CSV files to Parquet\n",
    "data_path = \"/Users/tommyly/network/data/embeddingdata/opencorporates/us_ny_unzipped\"\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_path = os.path.join(data_path, file)\n",
    "        parquet_path = os.path.join(data_path, file.replace('.csv', '.parquet'))\n",
    "        csv_to_parquet(csv_path, parquet_path)\n",
    "        print(f\"Converted {file} to Parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "data_path = \"/Users/tommyly/network/data/embeddingdata/opencorporates/us_ny_unzipped\"\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add company nodes\n",
    "companies = pq.read_table(os.path.join(data_path, 'companies.parquet'))\n",
    "company_data = companies.to_pydict()\n",
    "G.add_nodes_from([\n",
    "    (company_number, {'type': 'company', 'name': name})\n",
    "    for company_number, name in zip(company_data['company_number'], company_data['name'])\n",
    "])\n",
    "\n",
    "# Add officer nodes and edges\n",
    "officers = pq.read_table(os.path.join(data_path, 'officers.parquet'))\n",
    "officer_data = officers.to_pydict()\n",
    "G.add_nodes_from([\n",
    "    (f\"officer_{id}\", {'type': 'officer', 'name': f\"{first} {last}\"})\n",
    "    for id, first, last in zip(officer_data['id'], officer_data['first_name'], officer_data['last_name'])\n",
    "])\n",
    "G.add_edges_from([\n",
    "    (company, f\"officer_{id}\", {'relationship': position})\n",
    "    for company, id, position in zip(officer_data['company_number'], officer_data['id'], officer_data['position'])\n",
    "])\n",
    "\n",
    "# Add address edges\n",
    "addresses = pq.read_table(os.path.join(data_path, 'non_reg_addresses.parquet'))\n",
    "address_data = addresses.to_pydict()\n",
    "G.add_nodes_from([\n",
    "    (f\"address_{i}\", {'type': 'address', 'full_address': addr})\n",
    "    for i, addr in enumerate(address_data['in_full'])\n",
    "])\n",
    "G.add_edges_from([\n",
    "    (company, f\"address_{i}\", {'relationship': 'registered_at'})\n",
    "    for i, company in enumerate(address_data['company_number'])\n",
    "])\n",
    "\n",
    "# Print some basic network statistics\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"Is connected: {nx.is_connected(G)}\")\n",
    "print(f\"Number of connected components: {nx.number_connected_components(G)}\")\n",
    "\n",
    "# Save the graph\n",
    "nx.write_gexf(G, os.path.join(data_path, \"opencorporates_graph.gexf\"))\n",
    "print(\"Graph saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
